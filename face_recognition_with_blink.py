"""
H·ªá th·ªëng ƒëi·ªÉm danh nh·∫≠n di·ªán khu√¥n m·∫∑t v·ªõi Blink Detection
Ch·ªëng video replay b·∫±ng th·ª≠ th√°ch nh·∫•p nh√°y m·∫Øt ng·∫´u nhi√™n
"""
import cv2
import numpy as np
import os
import pickle
from datetime import datetime
import re

# Lazy import ƒë·ªÉ tr√°nh conflict
def get_deepface():
    """Lazy import DeepFace"""
    from deepface import DeepFace
    return DeepFace

# Import module advanced liveness detection
try:
    from advanced_liveness_module import perform_advanced_liveness_challenge, MEDIAPIPE_AVAILABLE
    LIVENESS_DETECTION_ENABLED = MEDIAPIPE_AVAILABLE
except ImportError:
    LIVENESS_DETECTION_ENABLED = False
    print("‚ö†Ô∏è Module advanced_liveness_module kh√¥ng t√¨m th·∫•y")


# ===========================
# CONSTANTS
# ===========================
KNOWN_FACES_DIR = "known_faces"
EMBEDDINGS_FILE = "face_embeddings.pkl"
ATTENDANCE_FILE = "attendance.csv"
THRESHOLD = 8.0  # Ng∆∞·ª°ng ph√°t hi·ªán
HAAR_CASCADE_PATH = cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'


# ===========================
# LOAD KNOWN FACES
# ===========================
def load_known_faces(force_reload=False):
    """
    Load embeddings c·ªßa c√°c khu√¥n m·∫∑t ƒë√£ bi·∫øt.
    T·ª± ƒë·ªông ph√°t hi·ªán ·∫£nh m·ªõi v√† c·∫≠p nh·∫≠t cache.
    H·ªó tr·ª£ nhi·ªÅu ·∫£nh cho m·ªói ng∆∞·ªùi: user_a.jpg, user_a_1.jpg, user_a_2.jpg
    """
    embeddings = {}
    
    # Ki·ªÉm tra cache
    if os.path.exists(EMBEDDINGS_FILE) and not force_reload:
        with open(EMBEDDINGS_FILE, 'rb') as f:
            embeddings = pickle.load(f)
        print(f"‚úÖ ƒê√£ load {len(embeddings)} embeddings t·ª´ cache")
    
    # L·∫•y danh s√°ch file hi·ªán t·∫°i
    current_files = {}
    if os.path.exists(KNOWN_FACES_DIR):
        for filename in os.listdir(KNOWN_FACES_DIR):
            if filename.lower().endswith(('.jpg', '.jpeg', '.png')):
                filepath = os.path.join(KNOWN_FACES_DIR, filename)
                current_files[filename] = os.path.getmtime(filepath)
    
    # Ki·ªÉm tra file m·ªõi ho·∫∑c ƒë√£ s·ª≠a
    need_update = False
    for filename, mtime in current_files.items():
        if filename not in embeddings or embeddings[filename][2] != mtime:
            need_update = True
            break
    
    # Ki·ªÉm tra file ƒë√£ x√≥a
    for filename in list(embeddings.keys()):
        if filename not in current_files:
            del embeddings[filename]
            need_update = True
            print(f"‚ùå ƒê√£ x√≥a: {filename}")
    
    # C·∫≠p nh·∫≠t n·∫øu c·∫ßn
    if need_update or force_reload:
        print("üîÑ ƒêang c·∫≠p nh·∫≠t embeddings...")
        DeepFace = get_deepface()
        
        for filename, mtime in current_files.items():
            if filename not in embeddings or embeddings[filename][2] != mtime:
                filepath = os.path.join(KNOWN_FACES_DIR, filename)
                
                # L·∫•y t√™n (x√≥a _s·ªë v√† extension)
                name = os.path.splitext(filename)[0]
                name = re.sub(r'_\d+$', '', name)  # X√≥a _1, _2, ...
                
                try:
                    # T√≠nh embedding
                    result = DeepFace.represent(
                        img_path=filepath,
                        model_name="Facenet",
                        enforce_detection=False
                    )
                    embedding = result[0]["embedding"]
                    embeddings[filename] = (name, embedding, mtime)
                    print(f"‚úÖ ƒê√£ load: {filename} -> {name}")
                except Exception as e:
                    print(f"‚ùå L·ªói khi load {filename}: {e}")
        
        # L∆∞u cache
        with open(EMBEDDINGS_FILE, 'wb') as f:
            pickle.dump(embeddings, f)
        print(f"üíæ ƒê√£ l∆∞u {len(embeddings)} embeddings v√†o cache")
    
    return embeddings


# ===========================
# FACE RECOGNITION
# ===========================
def recognize_face(face_embedding, known_embeddings):
    """
    So s√°nh embedding v·ªõi database.
    H·ªó tr·ª£ nhi·ªÅu ·∫£nh cho m·ªói ng∆∞·ªùi.
    """
    best_match = None
    min_distance = float('inf')
    
    # Group embeddings theo t√™n
    name_embeddings = {}
    for filename, (name, embedding, _) in known_embeddings.items():
        if name not in name_embeddings:
            name_embeddings[name] = []
        name_embeddings[name].append(embedding)
    
    # So s√°nh v·ªõi t·ª´ng ng∆∞·ªùi (l·∫•y kho·∫£ng c√°ch nh·ªè nh·∫•t trong t·∫•t c·∫£ ·∫£nh)
    for name, embeddings_list in name_embeddings.items():
        for ref_embedding in embeddings_list:
            distance = np.linalg.norm(
                np.array(face_embedding) - np.array(ref_embedding)
            )
            
            if distance < min_distance:
                min_distance = distance
                best_match = name
    
    # Ki·ªÉm tra threshold
    if min_distance < THRESHOLD:
        return best_match, min_distance
    else:
        return "Unknown", min_distance


# ===========================
# ATTENDANCE LOGGING
# ===========================
def log_attendance(name):
    """Ghi nh·∫≠n ƒëi·ªÉm danh v√†o CSV"""
    now = datetime.now()
    date_str = now.strftime("%Y-%m-%d")
    time_str = now.strftime("%H:%M:%S")
    
    # Ki·ªÉm tra ƒë√£ ƒëi·ªÉm danh h√¥m nay ch∆∞a
    if os.path.exists(ATTENDANCE_FILE):
        with open(ATTENDANCE_FILE, 'r', encoding='utf-8') as f:
            for line in f:
                if name in line and date_str in line:
                    print(f"‚ÑπÔ∏è  {name} ƒë√£ ƒëi·ªÉm danh h√¥m nay")
                    return False
    
    # Ghi attendance
    with open(ATTENDANCE_FILE, 'a', encoding='utf-8') as f:
        f.write(f"{name},{date_str},{time_str}\n")
    
    print(f"‚úÖ ƒê√£ ghi nh·∫≠n ƒëi·ªÉm danh: {name} - {date_str} {time_str}")
    return True


# ===========================
# MAIN
# ===========================
def main():
    print("="*60)
    print("   H·ªÜ TH·ªêNG ƒêI·ªÇM DANH NH·∫¨N DI·ªÜN KHU√îN M·∫∂T")
    print("   Advanced Liveness Detection - Ch·ªëng Video Replay")
    print("="*60)
    
    # Ki·ªÉm tra MediaPipe
    if not LIVENESS_DETECTION_ENABLED:
        print("\n‚ö†Ô∏è C·∫¢NH B√ÅO: Advanced Liveness Detection kh√¥ng kh·∫£ d·ª•ng!")
        print("   H·ªá th·ªëng s·∫Ω ch·∫°y KH√îNG C√ì anti-spoofing")
        print("   C√†i ƒë·∫∑t: pip install mediapipe")
        response = input("\nTi·∫øp t·ª•c kh√¥ng c√≥ liveness detection? (y/n): ")
        if response.lower() != 'y':
            print("‚ùå ƒê√£ h·ªßy")
            return
    else:
        print("\n‚úÖ Advanced Liveness Detection: ƒê√£ k√≠ch ho·∫°t")
        print("   - Random Blink Challenge")
        print("   - Random Head Movement Challenge")
        print("   - Texture Analysis")
    
    # Load known faces
    print(f"\nüìÇ ƒêang load khu√¥n m·∫∑t t·ª´: {KNOWN_FACES_DIR}")
    known_embeddings = load_known_faces()
    
    if not known_embeddings:
        print(f"‚ùå Kh√¥ng c√≥ khu√¥n m·∫∑t n√†o trong {KNOWN_FACES_DIR}")
        return
    
    # Hi·ªÉn th·ªã danh s√°ch
    names = set()
    for filename, (name, _, _) in known_embeddings.items():
        names.add(name)
    print(f"\nüë• C√≥ {len(names)} ng∆∞·ªùi: {', '.join(sorted(names))}")
    print(f"üì∑ T·ªïng {len(known_embeddings)} ·∫£nh tham chi·∫øu")
    
    # Kh·ªüi t·∫°o camera v√† face detector
    print("\nüìπ ƒêang kh·ªüi ƒë·ªông camera...")
    video_capture = cv2.VideoCapture(0)
    face_cascade = cv2.CascadeClassifier(HAAR_CASCADE_PATH)
    
    print("\n" + "="*60)
    print("H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG:")
    print("- ƒê∆∞a khu√¥n m·∫∑t v√†o tr∆∞·ªõc camera")
    print("- Nh·∫•n SPACE ƒë·ªÉ b·∫Øt ƒë·∫ßu nh·∫≠n di·ªán")
    if LIVENESS_DETECTION_ENABLED:
        print("- L√†m theo h∆∞·ªõng d·∫´n: Nh·∫•p nh√°y m·∫Øt HO·∫∂C Xoay ƒë·∫ßu")
        print("  (H·ªá th·ªëng s·∫Ω ch·ªçn ng·∫´u nhi√™n)")
    print("- Nh·∫•n 'q' ƒë·ªÉ tho√°t")
    print("="*60 + "\n")
    
    DeepFace = get_deepface()
    
    try:
        while True:
            ret, frame = video_capture.read()
            if not ret:
                print("‚ùå Kh√¥ng ƒë·ªçc ƒë∆∞·ª£c frame t·ª´ camera")
                break
            
            # Detect faces
            gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
            faces = face_cascade.detectMultiScale(
                gray,
                scaleFactor=1.1,
                minNeighbors=5,
                minSize=(100, 100)
            )
            
            # V·∫Ω khung
            for (x, y, w, h) in faces:
                cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
                cv2.putText(frame, "Nhan SPACE de nhan dien", 
                           (x, y-10), cv2.FONT_HERSHEY_SIMPLEX, 
                           0.5, (0, 255, 0), 2)
            
            # Hi·ªÉn th·ªã
            cv2.putText(frame, "Nhan SPACE: Nhan dien | Q: Thoat",
                       (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 
                       0.7, (255, 255, 255), 2)
            
            cv2.imshow('Face Recognition', frame)
            
            # X·ª≠ l√Ω ph√≠m
            key = cv2.waitKey(1) & 0xFF
            
            if key == ord('q'):
                print("\nüëã ƒê√£ tho√°t")
                break
            
            elif key == ord(' '):  # SPACE
                if len(faces) == 0:
                    print("‚ùå Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t!")
                    continue
                
                print("\n" + "="*60)
                print("üîç B·∫ÆT ƒê·∫¶U NH·∫¨N DI·ªÜN...")
                print("="*60)
                
                # Liveness Detection (n·∫øu c√≥)
                if LIVENESS_DETECTION_ENABLED:
                    print("\nüîê Th·ª±c hi·ªán Advanced Liveness Detection...")
                    success, message = perform_advanced_liveness_challenge(video_capture)
                    
                    if not success:
                        print(f"\n‚ùå TH·∫§T B·∫†I: {message}")
                        print("‚ö†Ô∏è  C√≥ th·ªÉ l√† video replay ho·∫∑c ·∫£nh in!")
                        continue
                    
                    print(f"\n‚úÖ Liveness Check: PASSED")
                
                # Nh·∫≠n di·ªán
                print("\nüîç ƒêang nh·∫≠n di·ªán khu√¥n m·∫∑t...")
                try:
                    # L·∫•y embedding
                    result = DeepFace.represent(
                        img_path=frame,
                        model_name="Facenet",
                        enforce_detection=False
                    )
                    
                    if not result:
                        print("‚ùå Kh√¥ng detect ƒë∆∞·ª£c khu√¥n m·∫∑t")
                        continue
                    
                    face_embedding = result[0]["embedding"]
                    
                    # So s√°nh
                    name, distance = recognize_face(face_embedding, known_embeddings)
                    
                    print(f"\nüìä K·∫øt qu·∫£:")
                    print(f"   Ng∆∞·ªùi: {name}")
                    print(f"   Distance: {distance:.2f}")
                    print(f"   Threshold: {THRESHOLD}")
                    
                    if name != "Unknown":
                        print(f"\n‚úÖ XIN CH√ÄO, {name.upper()}!")
                        log_attendance(name)
                    else:
                        print(f"\n‚ùå KH√îNG NH·∫¨N DI·ªÜN ƒê∆Ø·ª¢C")
                        print(f"   (Distance {distance:.2f} > Threshold {THRESHOLD})")
                
                except Exception as e:
                    print(f"‚ùå L·ªói khi nh·∫≠n di·ªán: {e}")
                
                print("="*60)
    
    finally:
        video_capture.release()
        cv2.destroyAllWindows()
        print("\n‚úÖ ƒê√£ ƒë√≥ng camera")


if __name__ == "__main__":
    main()
